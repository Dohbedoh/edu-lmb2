# Capture de sites WEB #

###### (d'après le Cahier des charges) ######
  * **- OK -**Aspirer et sauvegarder un site Web
  * **- OK -**Application Multi-Threadés :
    * **- OK -**possibilité de modifier le Nombre de Threads (Ressources)
    * **- OK -**possibilité de modifier le Nombre de Threads (Pages)
  * **- OK -**Contraintes de Profondeur
  * **- OK -**Contraintes de Taille :
    * **- OK -**maximale des fichiers HTML et PHP
    * **- OK -**maximale des autres fichiers
    * **- OK -**maximale du site
  * **- OK -**Contraintes de Filtres (extensions)

### La capture de site WEB doit permettre d'aspirer : ###

  * **- OK -**les pages HTML et PHP
  * **- OK -**les fichiers CSS ainsi que les images incluses dans les fichiers CSS
  * **- OK -**les fichiers JS
  * **- OK -**tout type d'images dont les extensions sont spécifiées (gif, ico, png, jpg, etc...)
  * **- OK -**tout type de documents dont les extensions sont spécifiées (pdf, doc, zip, etc...)
  * **- OK -**gérer les sessions HTTPS(nom d'utilisateur et mot de passe)
  * **- OK -**gérer les sessions Proxy(login, mdp, port, hôte)

### L'interface doit informer sur : ###

  * **- OK -**Les URL copiées
  * **- OK -**Les URL filtrées
  * **- OK -**Les URL pour lesquelles il y a eu des erreurs
  * **- OK -**Le nombre de pages à copier
  * **- OK -**Le nombre de pages copiées
  * **- OK -**Le nombre de ressources à copier
  * **- OK -**Le nombre de ressources copiées
  * **- OK -**Le temps d'exécution

### L'interface doit permettre de : ###

  * **- OK -**Stopper le Parser
  * **- OK -**Mettre en pause le Parser
  * **- OK -**Reprendre le Parsing en pause